{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35f8287-89a0-4ee0-a8a4-5a22d40b55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb702e09-8425-4d6e-8c76-c12ceb13dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('archive/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7473319-a03e-4b23-b84e-199a178a2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (416809, 3)\n",
      "\n",
      "Sample Data:\n",
      "   Unnamed: 0                                               text  label\n",
      "0           0      i just feel really helpless and heavy hearted      4\n",
      "1           1  ive enjoyed being able to slouch about relax a...      0\n",
      "2           2  i gave up my internship with the dmrg and am f...      4\n",
      "3           3                         i dont know i feel so lost      0\n",
      "4           4  i am a kindergarten teacher and i am thoroughl...      4\n"
     ]
    }
   ],
   "source": [
    "# Data Exploration\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nSample Data:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff35880e-9c02-4be9-9cb7-4567bd536c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899eed18-dd7c-46f1-a2e3-49f2026daa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# Assuming 'tweet' column contains the tweet text and 'emotion' column contains the emotion label\n",
    "tweets = data['text']\n",
    "emotions = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8fb8c7-d61b-430d-b94c-5c9bb4b52772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform tokenization, lowercasing, and removing punctuation\n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text\n",
    "\n",
    "tweets = tweets.apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455660e0-e418-4b4f-a412-6cc3b852f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance if necessary (e.g., using SMOTE)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, emotions, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode the target labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73cb40e6-a655-4601-ace4-97a888b065fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution in Training Set:\n",
      "1    112903\n",
      "0     96986\n",
      "3     45876\n",
      "4     38118\n",
      "2     27625\n",
      "5     11939\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the class distribution\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "print(pd.Series(y_train_encoded).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b9933f-709f-4594-bb34-9198f4cc14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b78853-8548-4164-b1bc-a607fc4d83be",
   "metadata": {},
   "source": [
    "# RNN Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8c4752-173c-4583-8b25-1a1b29f3de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl.metadata (849 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting dm-tree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gouthami\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl (377.0 MB)\n",
      "   ---------------------------------------- 0.0/377.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.6/377.0 MB 19.5 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 2.3/377.0 MB 29.4 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 4.4/377.0 MB 35.1 MB/s eta 0:00:11\n",
      "    --------------------------------------- 6.4/377.0 MB 37.3 MB/s eta 0:00:10\n",
      "    --------------------------------------- 8.5/377.0 MB 36.2 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 10.5/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 11.6/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 13.7/377.0 MB 38.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 14.8/377.0 MB 36.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 16.4/377.0 MB 34.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 18.3/377.0 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 20.4/377.0 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 22.1/377.0 MB 36.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 24.0/377.0 MB 36.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 26.3/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 27.9/377.0 MB 38.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 29.0/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 30.2/377.0 MB 34.6 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 32.2/377.0 MB 36.4 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 33.8/377.0 MB 36.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 35.5/377.0 MB 34.4 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 37.3/377.0 MB 32.7 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 39.1/377.0 MB 32.7 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 41.4/377.0 MB 38.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 43.3/377.0 MB 38.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 45.4/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 47.3/377.0 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 48.7/377.0 MB 43.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 51.0/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 53.2/377.0 MB 46.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 55.0/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 57.0/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 58.9/377.0 MB 43.7 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 60.4/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 62.4/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 63.9/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 66.1/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 67.8/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 70.0/377.0 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 71.8/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 74.1/377.0 MB 43.7 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 75.2/377.0 MB 46.7 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 76.7/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 78.7/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 80.5/377.0 MB 36.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 81.8/377.0 MB 34.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 83.8/377.0 MB 32.7 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 85.9/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 88.2/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 89.7/377.0 MB 38.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 91.4/377.0 MB 38.6 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 93.6/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 96.1/377.0 MB 46.9 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 98.1/377.0 MB 40.9 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 100.6/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 102.7/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ---------- ---------------------------- 105.3/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 107.5/377.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 110.1/377.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 112.3/377.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ----------- --------------------------- 114.5/377.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 116.5/377.0 MB 50.4 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 118.8/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 120.9/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 122.7/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 124.8/377.0 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 127.0/377.0 MB 46.9 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 129.3/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 131.7/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 134.1/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 135.7/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 138.0/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 139.5/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 141.8/377.0 MB 46.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 144.2/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 146.4/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 148.7/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 150.9/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "   --------------- ----------------------- 153.2/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 155.3/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 157.5/377.0 MB 50.4 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 159.5/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 161.5/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ---------------- ---------------------- 163.8/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 166.2/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 167.6/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 169.5/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 171.9/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 173.3/377.0 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 175.8/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 177.9/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "   ------------------ -------------------- 180.4/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 182.3/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 184.2/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 186.6/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 188.3/377.0 MB 46.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 190.3/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 192.4/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 194.3/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 196.6/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 199.1/377.0 MB 50.1 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 200.5/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 202.7/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 205.2/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 206.7/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 209.4/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 211.6/377.0 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 214.4/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 216.7/377.0 MB 50.1 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 219.1/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 221.4/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 223.0/377.0 MB 43.7 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 225.1/377.0 MB 46.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 227.5/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 229.8/377.0 MB 46.7 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 230.7/377.0 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 233.8/377.0 MB 43.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 236.2/377.0 MB 43.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 238.5/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 240.9/377.0 MB 54.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 243.3/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 245.5/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 247.9/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 250.0/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 252.8/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 254.5/377.0 MB 43.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 257.2/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 259.4/377.0 MB 50.4 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 261.1/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 261.1/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 261.1/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 261.5/377.0 MB 28.5 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 263.5/377.0 MB 28.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 266.1/377.0 MB 28.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 268.2/377.0 MB 28.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 270.0/377.0 MB 28.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 271.8/377.0 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 273.7/377.0 MB 46.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 276.0/377.0 MB 46.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 278.5/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 280.6/377.0 MB 43.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 282.8/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 285.0/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 286.7/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 288.9/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 291.2/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 292.6/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 294.7/377.0 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 297.3/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 299.6/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 302.0/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 304.4/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 306.8/377.0 MB 46.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 309.1/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 311.5/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 313.9/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 317.1/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 319.6/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 323.1/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 325.5/377.0 MB 46.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 328.0/377.0 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 330.5/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 333.0/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 334.2/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 336.4/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 338.7/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 340.3/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 342.7/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 344.8/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 347.4/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 349.6/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 351.6/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 353.6/377.0 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 355.3/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 357.5/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 359.9/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 361.7/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 363.4/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 365.1/377.0 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 367.3/377.0 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  370.3/377.0 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.4/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  374.8/377.0 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.6/377.0 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 377.0/377.0 MB 12.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.3/3.8 MB 73.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 40.6 MB/s eta 0:00:00\n",
      "Downloading h5py-3.10.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.5/2.7 MB 53.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 34.2 MB/s eta 0:00:00\n",
      "Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 33.0 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.0/24.4 MB 64.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.0/24.4 MB 43.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.4/24.4 MB 45.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.8/24.4 MB 47.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.6/24.4 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.1/24.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.0/24.4 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.1/24.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.3/24.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.9/24.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 43.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 34.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.7/127.7 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB ? eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.5 MB 45.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.5 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 43.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 46.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.3/101.3 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, dm-tree, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 dm-tree-0.1.8 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.0.5 libclang-16.0.6 ml-dtypes-0.3.2 namex-0.0.7 opt-einsum-3.3.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a2079fd-ba9b-40b1-b757-4f7cf493e0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd8926e-e65d-47c1-919f-79acf4078cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 10000  # Maximum number of words to keep in the vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ddfa9f-b7c0-4412-9140-56b9049afbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38b5df2-c54a-4649-b9d4-02f25be9119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform length\n",
    "max_sequence_length = 100  # Define your desired sequence length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7062db04-8dbb-481a-b08e-e08a320da123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_units = 64  # Number of units in the RNN layer\n",
    "\n",
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    SimpleRNN(units=hidden_units, activation='tanh'),\n",
    "    Dense(units=6, activation='softmax')  # Assuming 6 emotions to classify\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45b6581a-26f9-40af-b9d4-855783ce9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "377b2937-31a0-4102-9542-8b7fef9c3d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcba86d5-5fce-4718-a1c8-32c79691d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 22ms/step - accuracy: 0.7421 - loss: 0.7329 - val_accuracy: 0.9005 - val_loss: 0.3061\n",
      "Epoch 2/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 21ms/step - accuracy: 0.9025 - loss: 0.2835 - val_accuracy: 0.8956 - val_loss: 0.2777\n",
      "Epoch 3/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 21ms/step - accuracy: 0.9040 - loss: 0.2725 - val_accuracy: 0.8467 - val_loss: 0.4330\n",
      "Epoch 4/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 21ms/step - accuracy: 0.8717 - loss: 0.3865 - val_accuracy: 0.9097 - val_loss: 0.2381\n",
      "Epoch 5/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 21ms/step - accuracy: 0.9254 - loss: 0.1743 - val_accuracy: 0.9219 - val_loss: 0.1745\n",
      "Epoch 6/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 21ms/step - accuracy: 0.9318 - loss: 0.1434 - val_accuracy: 0.9239 - val_loss: 0.1358\n",
      "Epoch 7/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 21ms/step - accuracy: 0.9315 - loss: 0.1406 - val_accuracy: 0.9251 - val_loss: 0.1229\n",
      "Epoch 8/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 21ms/step - accuracy: 0.9382 - loss: 0.1077 - val_accuracy: 0.9250 - val_loss: 0.1435\n",
      "Epoch 9/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 21ms/step - accuracy: 0.9369 - loss: 0.1223 - val_accuracy: 0.9283 - val_loss: 0.1240\n",
      "Epoch 10/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 21ms/step - accuracy: 0.9093 - loss: 0.2198 - val_accuracy: 0.9144 - val_loss: 0.2147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21342aa0b90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Define the number of epochs\n",
    "batch_size = 64  # Define the batch size\n",
    "model_rnn.fit(X_train_padded, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0152563d-0c91-4fb1-92f3-84c38a1e65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2162\n",
      "Test Loss: 0.21466274559497833\n",
      "Test Accuracy: 0.9143974184989929\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_rnn.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19168b2f-6f2f-4eea-94aa-a9302a201491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10421/10421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5ms/step\n",
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "get_representation_rnn = Sequential(model_rnn.layers[:-1])  # Remove the output layer\n",
    "representations_train_rnn = get_representation_rnn.predict(X_train_padded)\n",
    "representations_test_rnn = get_representation_rnn.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74809025-0b56-4252-951c-7ca12deba473",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9afbce-7c46-42c5-ac35-542862100692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33a27924-d585-4f65-a018-7d96a989dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 10000  # Maximum number of words to keep in the vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33762b6a-8622-439e-a185-fd38c011c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f48c4e8b-a726-4850-9185-df1ab1b45f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform length\n",
    "max_sequence_length = 100  # Define your desired sequence length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83827c8a-f07b-4e74-b515-8010c2075628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_units = 64  # Number of units in the LSTM layer\n",
    "\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    LSTM(units=hidden_units),\n",
    "    Dense(units=6, activation='softmax')  # Assuming 6 emotions to classify\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "158904d0-db11-427c-bbba-5d7f1e2a974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e566056-6a64-4f8d-a627-a6097dc423a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb7b866-601b-4dd6-960a-34374d2a71e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 49ms/step - accuracy: 0.8181 - loss: 0.4568 - val_accuracy: 0.9363 - val_loss: 0.1000\n",
      "Epoch 2/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 49ms/step - accuracy: 0.9389 - loss: 0.0976 - val_accuracy: 0.9363 - val_loss: 0.1054\n",
      "Epoch 3/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 50ms/step - accuracy: 0.9399 - loss: 0.0918 - val_accuracy: 0.9387 - val_loss: 0.0952\n",
      "Epoch 4/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 50ms/step - accuracy: 0.9421 - loss: 0.0867 - val_accuracy: 0.9367 - val_loss: 0.0967\n",
      "Epoch 5/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 50ms/step - accuracy: 0.9433 - loss: 0.0850 - val_accuracy: 0.9346 - val_loss: 0.0959\n",
      "Epoch 6/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 51ms/step - accuracy: 0.9448 - loss: 0.0818 - val_accuracy: 0.9331 - val_loss: 0.0988\n",
      "Epoch 7/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 51ms/step - accuracy: 0.9455 - loss: 0.0810 - val_accuracy: 0.9275 - val_loss: 0.0990\n",
      "Epoch 8/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 51ms/step - accuracy: 0.9463 - loss: 0.0796 - val_accuracy: 0.9255 - val_loss: 0.1036\n",
      "Epoch 9/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 52ms/step - accuracy: 0.9469 - loss: 0.0785 - val_accuracy: 0.9285 - val_loss: 0.1081\n",
      "Epoch 10/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 52ms/step - accuracy: 0.9478 - loss: 0.0779 - val_accuracy: 0.9290 - val_loss: 0.1120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21342ab4190>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Define the number of epochs\n",
    "batch_size = 64  # Define the batch size\n",
    "model_lstm.fit(X_train_padded, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b03911cc-c243-4ba1-b0a0-3207453fef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 13ms/step - accuracy: 0.9287 - loss: 0.1124\n",
      "Test Loss: 0.11196041107177734\n",
      "Test Accuracy: 0.929008424282074\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_lstm.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7b98919-dad9-449f-b809-a8729700585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10421/10421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 12ms/step\n",
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "get_representation_lstm = Sequential(model_lstm.layers[:-1])  # Remove the output layer\n",
    "representations_train_lstm = get_representation_lstm.predict(X_train_padded)\n",
    "representations_test_lstm = get_representation_lstm.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686f3fe-b632-4773-a6ef-527ff371bfe4",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8999335-9b5f-4586-beaa-3083267d5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd01e717-f252-4b87-b3bc-0404fb0f6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "max_words = 10000  # Maximum number of words to keep in the vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cf2774a-3769-48c3-8078-d0b834e122b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to sequences\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2a1644-3381-4c0b-a506-1d5aa589aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform length\n",
    "max_sequence_length = 100  # Define your desired sequence length\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89a4dde4-32dd-4ad8-b041-0803e032407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GRU model\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_units = 64  # Number of units in the GRU layer\n",
    "\n",
    "model_gru = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    GRU(units=hidden_units),\n",
    "    Dense(units=6, activation='softmax')  # Assuming 6 emotions to classify\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aacb36ce-e86d-448d-8c5f-84d47b816b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_gru.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d64c4bf-3645-4e8a-97cf-90c7b91d003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d760b243-5e9b-45f3-bbe1-0444e22817d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 36ms/step - accuracy: 0.8372 - loss: 0.3971 - val_accuracy: 0.9391 - val_loss: 0.0964\n",
      "Epoch 2/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 38ms/step - accuracy: 0.9418 - loss: 0.0905 - val_accuracy: 0.9392 - val_loss: 0.0941\n",
      "Epoch 3/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 40ms/step - accuracy: 0.9425 - loss: 0.0869 - val_accuracy: 0.9399 - val_loss: 0.0928\n",
      "Epoch 4/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 41ms/step - accuracy: 0.9432 - loss: 0.0841 - val_accuracy: 0.9387 - val_loss: 0.0930\n",
      "Epoch 5/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - accuracy: 0.9450 - loss: 0.0814 - val_accuracy: 0.9392 - val_loss: 0.0928\n",
      "Epoch 6/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 40ms/step - accuracy: 0.9446 - loss: 0.0805 - val_accuracy: 0.9394 - val_loss: 0.0975\n",
      "Epoch 7/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 41ms/step - accuracy: 0.9457 - loss: 0.0792 - val_accuracy: 0.9353 - val_loss: 0.0977\n",
      "Epoch 8/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 40ms/step - accuracy: 0.9468 - loss: 0.0775 - val_accuracy: 0.9308 - val_loss: 0.1007\n",
      "Epoch 9/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 40ms/step - accuracy: 0.9469 - loss: 0.0768 - val_accuracy: 0.9294 - val_loss: 0.1049\n",
      "Epoch 10/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 40ms/step - accuracy: 0.9474 - loss: 0.0769 - val_accuracy: 0.9256 - val_loss: 0.1083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23df315de10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Define the number of epochs\n",
    "batch_size = 64  # Define the batch size\n",
    "model_gru.fit(X_train_padded, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "963aafb0-9f34-4c89-a982-7f74b8167cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9255 - loss: 0.1074\n",
      "Test Loss: 0.10832192003726959\n",
      "Test Accuracy: 0.9256495833396912\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_gru.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37dcaa2c-341f-41b5-b706-bc1ef5e015fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10421/10421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step\n",
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "get_representation_gru = Sequential(model_gru.layers[:-1])  # Remove the output layer\n",
    "representations_train_gru = get_representation_gru.predict(X_train_padded)\n",
    "representations_test_gru = get_representation_gru.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6c9f8-e3c2-4c99-84b5-98e1d84e795f",
   "metadata": {},
   "source": [
    "# bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1286bfc-2e72-44a0-aa1b-96783ddb9372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f34dbe3d-1192-4bc9-9096-5eea49ce026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bi-LSTM model\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_units = 64  # Number of units in the LSTM layer\n",
    "\n",
    "model_bi_lstm = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    Bidirectional(LSTM(units=hidden_units)),\n",
    "    Dense(units=6, activation='softmax')  # Assuming 6 emotions to classify\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15f1a81e-3c80-45a6-9f1f-09d9a0d5cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_bi_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1f53991-9b14-48c9-80ef-f4c0c8887b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model_bi_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bde8ba1-1570-4c5c-a6b4-ba42b15d2649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 46ms/step - accuracy: 0.8230 - loss: 0.4422 - val_accuracy: 0.9359 - val_loss: 0.1052\n",
      "Epoch 2/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 46ms/step - accuracy: 0.9384 - loss: 0.0971 - val_accuracy: 0.9385 - val_loss: 0.0959\n",
      "Epoch 3/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 47ms/step - accuracy: 0.9423 - loss: 0.0891 - val_accuracy: 0.9369 - val_loss: 0.0943\n",
      "Epoch 4/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 48ms/step - accuracy: 0.9439 - loss: 0.0854 - val_accuracy: 0.9359 - val_loss: 0.0944\n",
      "Epoch 5/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 47ms/step - accuracy: 0.9444 - loss: 0.0828 - val_accuracy: 0.9331 - val_loss: 0.0960\n",
      "Epoch 6/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 48ms/step - accuracy: 0.9444 - loss: 0.0819 - val_accuracy: 0.9300 - val_loss: 0.0981\n",
      "Epoch 7/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 47ms/step - accuracy: 0.9461 - loss: 0.0803 - val_accuracy: 0.9317 - val_loss: 0.1021\n",
      "Epoch 8/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 45ms/step - accuracy: 0.9461 - loss: 0.0802 - val_accuracy: 0.9227 - val_loss: 0.1046\n",
      "Epoch 9/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 46ms/step - accuracy: 0.9474 - loss: 0.0784 - val_accuracy: 0.9215 - val_loss: 0.1063\n",
      "Epoch 10/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 48ms/step - accuracy: 0.9482 - loss: 0.0772 - val_accuracy: 0.9289 - val_loss: 0.1128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23d80424190>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Define the number of epochs\n",
    "batch_size = 64  # Define the batch size\n",
    "model_bi_lstm.fit(X_train_padded, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69f7414e-acdd-4a9e-b38b-1539538d3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - accuracy: 0.9290 - loss: 0.1121\n",
      "Test Loss: 0.11276523023843765\n",
      "Test Accuracy: 0.9288764595985413\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_bi_lstm.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962a7ba3-aa44-4323-84f7-051e9e15b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10421/10421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step\n",
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "get_representation_bi_lstm = Sequential(model_bi_lstm.layers[:-1])  # Remove the output layer\n",
    "representations_train_bi_lstm = get_representation_bi_lstm.predict(X_train_padded)\n",
    "representations_test_bi_lstm = get_representation_bi_lstm.predict(X_test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4caeb60-5f57-4b16-b0bc-47a5cba7deaa",
   "metadata": {},
   "source": [
    "# bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a01b97e1-1eae-4a31-a068-864d8ce73d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18880018-9dfb-4972-9716-5bd209d43f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bi-GRU model\n",
    "embedding_dim = 100  # Dimension of word embeddings\n",
    "hidden_units = 64  # Number of units in the GRU layer\n",
    "\n",
    "model_bi_gru = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
    "    Bidirectional(GRU(units=hidden_units)),\n",
    "    Dense(units=6, activation='softmax')  # Assuming 6 emotions to classify\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72d096d9-de05-4ad6-9d97-c7466dd831fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_bi_gru.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2696eaa-6215-4985-a72f-866ed6ab4f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(model_bi_gru.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc0f55ec-991b-403c-a6e4-0d2f9951b945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 78ms/step - accuracy: 0.8428 - loss: 0.3833 - val_accuracy: 0.9385 - val_loss: 0.0952\n",
      "Epoch 2/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 74ms/step - accuracy: 0.9408 - loss: 0.0926 - val_accuracy: 0.9397 - val_loss: 0.0925\n",
      "Epoch 3/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 76ms/step - accuracy: 0.9418 - loss: 0.0889 - val_accuracy: 0.9378 - val_loss: 0.0936\n",
      "Epoch 4/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 76ms/step - accuracy: 0.9440 - loss: 0.0835 - val_accuracy: 0.9382 - val_loss: 0.0927\n",
      "Epoch 5/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 78ms/step - accuracy: 0.9442 - loss: 0.0812 - val_accuracy: 0.9384 - val_loss: 0.0944\n",
      "Epoch 6/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 76ms/step - accuracy: 0.9448 - loss: 0.0804 - val_accuracy: 0.9375 - val_loss: 0.0964\n",
      "Epoch 7/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 78ms/step - accuracy: 0.9452 - loss: 0.0792 - val_accuracy: 0.9355 - val_loss: 0.0982\n",
      "Epoch 8/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 77ms/step - accuracy: 0.9467 - loss: 0.0777 - val_accuracy: 0.9360 - val_loss: 0.1017\n",
      "Epoch 9/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 76ms/step - accuracy: 0.9464 - loss: 0.0776 - val_accuracy: 0.9346 - val_loss: 0.1044\n",
      "Epoch 10/10\n",
      "\u001b[1m5211/5211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 78ms/step - accuracy: 0.9482 - loss: 0.0764 - val_accuracy: 0.9280 - val_loss: 0.1050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23d80946b10>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Define the number of epochs\n",
    "batch_size = 64  # Define the batch size\n",
    "model_bi_gru.fit(X_train_padded, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_test_padded, y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57423977-64b0-46ab-af6b-3d8929f80fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 13ms/step - accuracy: 0.9274 - loss: 0.1062\n",
      "Test Loss: 0.10495075583457947\n",
      "Test Accuracy: 0.9280247688293457\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model_bi_gru.evaluate(X_test_padded, y_test_encoded)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "721967e2-2198-468a-b521-1c8b496a8c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10421/10421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 12ms/step\n",
      "\u001b[1m2606/2606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Obtain representations\n",
    "get_representation_bi_gru = Sequential(model_bi_gru.layers[:-1])  # Remove the output layer\n",
    "representations_train_bi_gru = get_representation_bi_gru.predict(X_train_padded)\n",
    "representations_test_bi_gru = get_representation_bi_gru.predict(X_test_padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
